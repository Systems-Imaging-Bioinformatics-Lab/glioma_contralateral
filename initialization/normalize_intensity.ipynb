{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ncwang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from nipype.interfaces.ants import N4BiasFieldCorrection\n",
    "# import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.morphology import binary_dilation, binary_erosion\n",
    "from copy import deepcopy\n",
    "\n",
    "#from nipy import labs\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import iqr\n",
    "import glob\n",
    "import warnings # for file system warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import file_structure\n",
    "(origdir,basedir,imagedir,normdir,savedir,train_dir,val_dir,test_dir) = file_structure.file_dirs()\n",
    "os.chdir(imagedir)\n",
    "\n",
    "patients = []\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    for dn in dirs:\n",
    "        patients.append(os.path.join(root,dn))\n",
    "#normalized_dir = '/rsrch1/bcb/Imaging-Genomics_SIBL/DONNIE_KIM/Brachy_deep_learning/IDH_Prediction/data/normalized_data/'\n",
    "os.chdir(origdir)\n",
    "\n",
    "def normalize(p):\n",
    "\n",
    "    print(p, patients[p])\n",
    "    patient_dir = os.path.abspath(os.path.join(imagedir,patients[p]))\n",
    "    patient_norm_dir = os.path.abspath(os.path.join(normdir,patients[p]))\n",
    "    \n",
    "    print(patient_norm_dir)\n",
    "    #os.chdir(patient_dir)\n",
    "    #print(patient_dir)\n",
    "    \n",
    "    # wildcard search\n",
    "    #segTest = os.path.join(patient_dir,'*seg.nii.gz')\n",
    "    #segTest = os.path.join(patient_dir,'*GlistrBoost_ManuallyCorrected.nii.gz')\n",
    "    segTest = os.path.join(patient_dir,'*truth.nii.gz')\n",
    "    segFiles = glob.glob(segTest)\n",
    "    #normalize image intensity values relative to normal brain\n",
    "    if not segFiles: # no files found\n",
    "        print(segTest)\n",
    "        segTest = os.path.join(patient_dir,'*GlistrBoost.nii.gz')\n",
    "        segFiles = glob.glob(segTest)\n",
    "        if not segFiles: # no files found\n",
    "            print(segTest)\n",
    "            return # require the truth file to exist\n",
    "\n",
    "    if (len(segFiles) > 1): # glob is unsorted... throw a warning if multiple files found, pick the first one\n",
    "        warnings.warn('Multiple files found, %s used' % (segFiles[0]))\n",
    "        \n",
    "    truth = nib.load(segFiles[0]).get_data()\n",
    "    if not os.path.exists(patient_norm_dir):\n",
    "        os.makedirs(patient_norm_dir)\n",
    "    idx_mask = np.where(truth==0)\n",
    "    out_name = os.path.abspath(os.path.join(patient_norm_dir,'truth.npy'))\n",
    "    np.save(out_name, truth)\n",
    "    \n",
    "    # wildcard search\n",
    "    flairTest = os.path.join(patient_dir,'*flair.nii.gz')\n",
    "    flairFiles = glob.glob(flairTest)\n",
    "    if flairTest: # file(s) found\n",
    "        if (len(flairFiles) > 1): # glob is unsorted... throw a warning if multiple files found, pick the first one\n",
    "            warnings.warn('Multiple files found, %s used' % (flairFiles[0]))\n",
    "        FLAIR_ss = np.float64(np.round(nib.load(flairFiles[0]).get_data())) # try to save the flair version\n",
    "        idx_nz = np.nonzero(FLAIR_ss[idx_mask])\n",
    "        median = np.median(FLAIR_ss[idx_mask][idx_nz])\n",
    "        curr_iqr = iqr(FLAIR_ss[idx_mask][idx_nz])\n",
    "        FLAIR_normssn4 = deepcopy(FLAIR_ss)\n",
    "        FLAIR_normssn4[np.nonzero(FLAIR_ss)] = (FLAIR_normssn4[np.nonzero(FLAIR_ss)]-median)/curr_iqr\n",
    "        out_name = os.path.abspath(os.path.join(patient_norm_dir,'FLAIR_normssn4.npy'))\n",
    "        np.save(out_name,FLAIR_normssn4)\n",
    "    \n",
    "    # wildcard search\n",
    "    t2Test = os.path.join(patient_dir,'*t2.nii.gz')\n",
    "    t2Files = glob.glob(t2Test)\n",
    "    if t2Files: # file(s) found\n",
    "        if (len(t2Files) > 1): # glob is unsorted... throw a warning if multiple files found, pick the first one\n",
    "            warnings.warn('Multiple files found, %s used' % (t2Files[0]))\n",
    "        T2_ss = np.float64(np.round(nib.load(t2Files[0]).get_data()))# try to save the t2 version\n",
    "        idx_nz = np.nonzero(T2_ss[idx_mask])\n",
    "        median = np.median(T2_ss[idx_mask][idx_nz])\n",
    "        curr_iqr = iqr(T2_ss[idx_mask][idx_nz])\n",
    "        T2_normssn4 = deepcopy(T2_ss)\n",
    "        T2_normssn4[np.nonzero(T2_ss)] = (T2_normssn4[np.nonzero(T2_ss)]-median)/curr_iqr\n",
    "        out_name = os.path.abspath(os.path.join(patient_norm_dir,'T2_normssn4.npy'))\n",
    "        np.save(out_name,T2_normssn4)\n",
    "\n",
    "    # wildcard search\n",
    "    t1Test = os.path.join(patient_dir,'*t1.nii.gz')\n",
    "    t1Files = glob.glob(t1Test)\n",
    "    if t1Files: # file(s) found\n",
    "        if (len(t1Files) > 1): # glob is unsorted... throw a warning if multiple files found, pick the first one\n",
    "            warnings.warn('Multiple files found, %s used' % (t1Files[0]))\n",
    "        T1_ss = np.float64(np.round(nib.load(t1Files[0]).get_data()))# try to save the t1 version\n",
    "        idx_nz = np.nonzero(T1_ss[idx_mask])\n",
    "        median = np.median(T1_ss[idx_mask][idx_nz])\n",
    "        curr_iqr = iqr(T1_ss[idx_mask][idx_nz])\n",
    "        T1_normssn4 = deepcopy(T1_ss)\n",
    "        T1_normssn4[np.nonzero(T1_ss)] = (T1_normssn4[np.nonzero(T1_ss)]-median)/curr_iqr   \n",
    "        out_name = os.path.abspath(os.path.join(patient_norm_dir,'T1_normssn4.npy'))\n",
    "        np.save(out_name,T1_normssn4)\n",
    "    \n",
    "    # wildcard search\n",
    "    t1GdTest = os.path.join(patient_dir,'*t1Gd.nii.gz')\n",
    "    t1GdFiles = glob.glob(t1GdTest)\n",
    "    if t1GdFiles: # file(s) found\n",
    "        if (len(t1GdFiles) > 1): # glob is unsorted... throw a warning if multiple files found, pick the first one\n",
    "            warnings.warn('Multiple files found, %s used' % (t1GdFiles[0]))\n",
    "        T1post_ss = np.float64(np.round(nib.load(t1GdFiles[0]).get_data()))\n",
    "        idx_nz = np.nonzero(T1post_ss[idx_mask])\n",
    "        median = np.median(T1post_ss[idx_mask][idx_nz])\n",
    "        curr_iqr = iqr(T1post_ss[idx_mask][idx_nz])\n",
    "        T1post_normssn4 = deepcopy(T1post_ss)\n",
    "        T1post_normssn4[np.nonzero(T1post_ss)] = (T1post_normssn4[np.nonzero(T1post_ss)]-median)/curr_iqr     \n",
    "        out_name = os.path.abspath(os.path.join(patient_norm_dir,'T1post_normssn4.npy'))\n",
    "        np.save(out_name,T1post_normssn4)         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#basedir = '/rsrch1/bcb/Imaging-Genomics_SIBL/DONNIE_KIM/Brachy_deep_learning/IDH_Prediction/data/image_data/'\n",
    "\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "Parallel(n_jobs=num_cores)(delayed(normalize)(p) for p in range(len(patients)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalized_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ba780be7eb25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpatient_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagedir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpatient_norm_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatient_norm_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'normalized_dir' is not defined"
     ]
    }
   ],
   "source": [
    "p = 4\n",
    "\n",
    "patient_dir = os.path.abspath(os.path.join(imagedir,patients[p]))\n",
    "patient_norm_dir = os.path.abspath(os.path.join(normalized_dir,patients[p]))\n",
    "\n",
    "print(patient_norm_dir)\n",
    "#os.chdir(patient_dir)\n",
    "#print(patient_dir)\n",
    "\n",
    "# wildcard search\n",
    "#segTest = os.path.join(patient_dir,'*seg.nii.gz')\n",
    "#segTest = os.path.join(patient_dir,'*GlistrBoost_ManuallyCorrected.nii.gz')\n",
    "segTest = os.path.join(patient_dir,'*truth.nii.gz')\n",
    "segFiles = glob.glob(segTest)\n",
    "#normalize image intensity values relative to normal brain\n",
    "if not segFiles: # no files found\n",
    "    print(segTest)\n",
    "    segTest = os.path.join(patient_dir,'*GlistrBoost.nii.gz')\n",
    "    segFiles = glob.glob(segTest)\n",
    "    if not segFiles: # no files found\n",
    "        print(segTest)\n",
    "\n",
    "if (len(segFiles) > 1): # glob is unsorted... throw a warning if multiple files found, pick the first one\n",
    "    warnings.warn('Multiple files found, %s used' % (segFiles[0]))\n",
    "\n",
    "truth = nib.load(segFiles[0]).get_data()\n",
    "if not os.path.exists(patient_norm_dir):\n",
    "    os.makedirs(patient_norm_dir)\n",
    "idx_mask = np.where(truth==0)\n",
    "out_name = os.path.abspath(os.path.join(patient_norm_dir,'truth.npy'))\n",
    "np.save(out_name, truth)\n",
    "\n",
    "\n",
    "# wildcard search\n",
    "t1Test = os.path.join(patient_dir,'*t1.nii.gz')\n",
    "t1Files = glob.glob(t1Test)\n",
    "if t1Files: # file(s) found\n",
    "    if (len(t1Files) > 1): # glob is unsorted... throw a warning if multiple files found, pick the first one\n",
    "        warnings.warn('Multiple files found, %s used' % (t1Files[0]))\n",
    "    T1_ss = np.round(nib.load(t1Files[0]).get_data())# try to save the t1 version\n",
    "    idx_nz = np.nonzero(T1_ss[idx_mask])\n",
    "    median = np.median(T1_ss[idx_mask][idx_nz])\n",
    "    curr_iqr = iqr(T1_ss[idx_mask][idx_nz])\n",
    "    T1_normssn4 = deepcopy(T1_ss)\n",
    "    T1_normssn4[np.nonzero(T1_ss)] = np.float(T1_normssn4[np.nonzero(T1_ss)]-median)/curr_iqr   \n",
    "    out_name = os.path.abspath(os.path.join(patient_norm_dir,'T1_normssn4.npy'))\n",
    "    np.save(out_name,T1_normssn4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_ss = np.float64(np.round(nib.load(t1Files[0]).get_data()))\n",
    "T1_normssn4 = deepcopy(T1_ss)\n",
    "T1_normssn4[np.nonzero(T1_ss)] = (T1_normssn4[np.nonzero(T1_ss)]-median)/curr_iqr  \n",
    "print(np.unique(T1_normssn4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
