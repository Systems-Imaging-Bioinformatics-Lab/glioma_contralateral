{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ncwang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0\n",
      " 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0\n",
      " 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 # conda install opencv\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.interpolate as interpolate\n",
    "#basedir = '/Users/Nick/Documents/MATLAB/Rao Lab/normalized_data/'\n",
    "# load data and labels\n",
    "import file_structure\n",
    "\n",
    "def zoompad(array, desired_size):\n",
    "    array = cv2.resize(array,(desired_size[0],desired_size[1]))\n",
    "    return array\n",
    "\n",
    "(origdir,basedir,imagedir,normdir,savedir) = file_structure.file_dirs()\n",
    "\n",
    "os.chdir(imagedir)\n",
    "\n",
    "#patients=next(os.walk('.'))[1]\n",
    "p_dirs = []\n",
    "patients = []\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    for dn in dirs:\n",
    "        patients.append(dn)\n",
    "        p_dirs.append(os.path.join(root,dn))\n",
    "\n",
    "\n",
    "# obtain top 50 percentile images\n",
    "\n",
    "#Load a spreadsheet with patient ID in the first column, age in the third column, and IDH status in the second column\n",
    "#xl = pd.ExcelFile('/Users/Nick/Documents/MATLAB/Rao Lab/clinical_data_IDH1_1p19q.xlsx')\n",
    "xl = pd.ExcelFile(os.path.join(basedir,'data','clinical_data_v2.xlsx'))\n",
    "df = np.asarray(xl.parse(\"S1A. TCGA discovery dataset\"))\n",
    "#pIdxs =np.arange(np.asarray(df[:,0]).shape[0])[np.in1d(df[:,0],patients)]\n",
    "pMask = np.in1d(df[:,0],patients)\n",
    "#print(df)\n",
    "#print(df[:,0])\n",
    "#print(patients)\n",
    "#print(np.intersect1d(df[:,0],patients))\n",
    "#print(pIdxs)\n",
    "dfFilt = df[pMask,:] # filter out the rows of the excel file that don't have imaging information\n",
    "\n",
    "dirIdxs =np.arange(np.asarray(patients).shape[0])[np.in1d(patients,df[:,0])] # filter out the directories \n",
    "\n",
    "patients = [patients[i] for i in dirIdxs] # lists have to be handled differently\n",
    "p_dirs = [p_dirs[i] for i in dirIdxs] \n",
    "\n",
    "#print(dfFilt)\n",
    "patient_age = dfFilt[:,[0,14]]\n",
    "patient_IDH = dfFilt[:,[0,21]]\n",
    "patient_1p19q = dfFilt[:,[0,22]]\n",
    "patient_IDH1_1p19q = dfFilt[:,[0,23]]\n",
    "patient_OS = dfFilt[:,[0,16]]\n",
    "patient_gender = dfFilt[:,[0,15]]\n",
    "patient_KPS = dfFilt[:,[0,18]]\n",
    "kps_mask = pd.isnull(patient_KPS[:,1])\n",
    "patient_KPS[kps_mask,1] = 80 # impute KPS when nan to 80\n",
    "                                 \n",
    "print(patient_1p19q[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_size=[142,142]\n",
    "\n",
    "# obtain the ratio between codel and non_codel\n",
    "nn_patient_1p19q = patient_1p19q[~pd.isnull(patient_1p19q[:,1]),:]\n",
    "num_codel = np.count_nonzero(nn_patient_1p19q[:,1])\n",
    "num_non_codel = len(nn_patient_1p19q[:,1])- num_codel\n",
    "print(num_codel)\n",
    "print(num_non_codel)\n",
    "#codel: non_codel = 13:130 = 1:10\n",
    "\n",
    "# for balancing purpose between codel vs non-codel cases, extract 30 codel per 3 non-codel case => 50:50\n",
    "\n",
    "# pre allocate arrays for codel and non codel separately\n",
    "\n",
    "# case: non-codel 130*3 = 390\n",
    "\n",
    "non_codel_factor = 2\n",
    "\n",
    "\n",
    "slices_FLAIR = np.empty([num_non_codel*non_codel_factor, desired_size[0], desired_size[1], 3])\n",
    "slices_T2 = np.empty([num_non_codel*non_codel_factor, desired_size[0], desired_size[1], 3])\n",
    "slices_T1 = np.empty([num_non_codel*non_codel_factor, desired_size[0], desired_size[1], 3])\n",
    "slices_T1post = np.empty([num_non_codel*non_codel_factor, desired_size[0], desired_size[1], 3])\n",
    "slices_mask = np.empty([num_non_codel*non_codel_factor, desired_size[0], desired_size[1], 3])\n",
    "\n",
    "label_age = np.empty(num_non_codel*non_codel_factor)\n",
    "label_IDH1 = np.empty(num_non_codel*non_codel_factor)\n",
    "label_1p19q = np.empty(num_non_codel*non_codel_factor)\n",
    "label_IDH1_1p19q = np.empty(num_non_codel*non_codel_factor)\n",
    "label_OS = np.empty(num_non_codel*non_codel_factor)\n",
    "label_gender = np.empty(num_non_codel*non_codel_factor)\n",
    "label_KPS = np.empty(num_non_codel*non_codel_factor) \n",
    "label_id = np.empty(num_non_codel*non_codel_factor) \n",
    "label_idstr = np.empty(num_non_codel*non_codel_factor,dtype=object) \n",
    "print(label_gender.shape)\n",
    "print(num_non_codel*non_codel_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codel_factor = 20\n",
    "\n",
    "slices_FLAIR_codel = np.empty([num_codel*codel_factor, desired_size[0], desired_size[1], 3])\n",
    "slices_T2_codel = np.empty([num_codel*codel_factor, desired_size[0], desired_size[1], 3])\n",
    "slices_T1_codel = np.empty([num_codel*codel_factor, desired_size[0], desired_size[1], 3])\n",
    "slices_T1post_codel = np.empty([num_codel*codel_factor, desired_size[0], desired_size[1], 3])\n",
    "slices_mask_codel = np.empty([num_non_codel*non_codel_factor, desired_size[0], desired_size[1], 3])\n",
    "\n",
    "label_age_codel = np.empty(num_codel*codel_factor)\n",
    "label_IDH1_codel = np.empty(num_codel*codel_factor)\n",
    "label_1p19q_codel = np.empty(num_codel*codel_factor)\n",
    "label_IDH1_1p19q_codel = np.empty(num_codel*codel_factor)\n",
    "label_OS_codel = np.empty(num_codel*codel_factor)\n",
    "label_gender_codel = np.empty(num_codel*codel_factor)\n",
    "label_KPS_codel = np.empty(num_codel*codel_factor) \n",
    "label_id_codel = np.empty(num_codel*codel_factor) \n",
    "label_idstr_codel = np.empty(num_codel*codel_factor,dtype=object) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counters\n",
    "codel_counter = 0\n",
    "non_codel_counter = 0\n",
    "used_sl_idx_arr = np.empty((0,1))\n",
    "#for p in range(3):#range(len(patients)):\n",
    "for p in range(len(patients)):\n",
    "    #p_bdir = os.path.basename(patients[p])\n",
    "    #p_bdir = patients[p]\n",
    "    #p_id = p_bdir # new set matches IDs, though some transformation may be needed in the future\n",
    "    p_id = patients[p]\n",
    "    patient_dir = os.path.join(normdir,p_dirs[p])\n",
    "\n",
    "    print(p, p_id,patient_dir)\n",
    "    idx_idh1=np.asarray(np.where((patient_IDH[:,0].astype(str))==str(p_id)))\n",
    "    if (idx_idh1.size == 0): # not found in the spreadsheet\n",
    "        print(\"\\\"%s\\\" not found in Excel Spreadsheet\" % (p_id))\n",
    "        continue # skip this folder\n",
    "    \n",
    "    curr_idh1 = patient_IDH[idx_idh1,1]\n",
    "    if curr_idh1 == 'WT':\n",
    "        curr_idh1 = 0\n",
    "    elif curr_idh1 == 'Mutant':\n",
    "        curr_idh1 = 1\n",
    "    elif not (curr_idh1 == 1 or curr_idh1 == 0):\n",
    "        curr_idh1 = float('nan')\n",
    "\n",
    "    idx_age=np.asarray(np.where((patient_age[:,0].astype(str))==str(p_id)))\n",
    "    curr_age = patient_age[idx_age,1]\n",
    "\n",
    "    idx_1p19q=np.asarray(np.where((patient_1p19q[:,0].astype(str))==str(p_id)))\n",
    "    curr_1p19q = patient_1p19q[idx_1p19q,1]\n",
    "\n",
    "    idx_IDH1_1p19q=np.asarray(np.where((patient_IDH1_1p19q[:,0].astype(str))==str(p_id)))\n",
    "    curr_IDH1_1p19q = patient_IDH1_1p19q[idx_IDH1_1p19q,1]\n",
    "    if curr_IDH1_1p19q == 'IDHwt':\n",
    "        curr_IDH1_1p19q = 0\n",
    "    elif curr_IDH1_1p19q == 'IDHmut-non-codel':\n",
    "        curr_IDH1_1p19q = 1\n",
    "    elif curr_IDH1_1p19q == 'IDHmut-codel':\n",
    "        curr_IDH1_1p19q = 2\n",
    "    elif not (curr_IDH1_1p19q == 1 or curr_IDH1_1p19q == 0):\n",
    "        curr_IDH1_1p19q = float('nan')\n",
    "\n",
    "    idx_OS=np.asarray(np.where((patient_OS[:,0].astype(str))==str(p_id)))\n",
    "    curr_OS = patient_OS[idx_OS,1]\n",
    "\n",
    "    idx_gender=np.asarray(np.where((patient_gender[:,0].astype(str))==str(p_id)))\n",
    "    input_gender=patient_gender[idx_gender,1] # if handling a string, and you put in a float, things get ugly when you delete\n",
    "    if input_gender == 'male':\n",
    "        curr_gender = np.float64(0)\n",
    "    elif input_gender == 'female':\n",
    "        curr_gender = np.float64(1)\n",
    "    elif not (input_gender == 1 or input_gender == 0):\n",
    "        curr_gender = float('nan')\n",
    "        #print('nan')\n",
    "    else:\n",
    "        curr_gender = input_gender\n",
    "    \n",
    "    if not (curr_gender == 1 or curr_gender == 0):\n",
    "        print(curr_gender)\n",
    "    idx_KPS=np.asarray(np.where((patient_KPS[:,0].astype(str))==str(p_id)))\n",
    "    curr_KPS=patient_KPS[idx_KPS,1]\n",
    "\n",
    "    os.chdir(patient_dir)\n",
    "    FLAIR = np.load('FLAIR_normssn4.npy')\n",
    "    T2 = np.load('T2_normssn4.npy')\n",
    "    T1 = np.load('T1_normssn4.npy')\n",
    "    T1post = np.load('T1post_normssn4.npy')\n",
    "    mask = np.load('truth.npy')\n",
    "\n",
    "    #FLAIR = nib.load('flair.nii.gz').get_data()\n",
    "    #T2 = nib.load('t2.nii.gz').get_data()\n",
    "    #T1 = nib.load('t1.nii.gz').get_data()\n",
    "    #T1post = nib.load('t1Gd.nii.gz').get_data()\n",
    "    #mask = nib.load('truth.nii.gz').get_data()\n",
    "\n",
    "    # mask label is organized as following: 1 = non-enhancing, 2 = edema, 4 = enhancing \n",
    "    mask[mask==2] = 1\n",
    "    mask[mask==4] = 1\n",
    "\n",
    "    FLAIR_m= FLAIR\n",
    "    T2_m= T2\n",
    "    T1_m= T1\n",
    "    T1post_m= T1post\n",
    "\n",
    "    #Find the largest, 75th, and 50th percentile slices in each dimension\n",
    "    x_sum=np.sum(mask,axis=(1,2))\n",
    "    y_sum=np.sum(mask,axis=(0,2))\n",
    "    z_sum=np.sum(mask,axis=(0,1))\n",
    "\n",
    "    #Check if the patient is codel or non-codel (1 or 0). The ratio between codel and non-codel is 13:130\n",
    "    #So, subsample codel cases 10 times more than codel\n",
    "\n",
    "    if curr_1p19q == 0: #i.e. if non-codel case, subsample 100,75, and 50 percentile\n",
    "\n",
    "        xp100=np.percentile(x_sum[np.nonzero(x_sum)],100,interpolation='nearest')\n",
    "        xp75=np.percentile(x_sum[np.nonzero(x_sum)],75,interpolation='nearest')\n",
    "        # xp50=np.percentile(x_ m[np.nonzero(x_sum)],50,interpolation='nearest')\n",
    "        yp100=np.percentile(y_sum[np.nonzero(y_sum)],100,interpolation='nearest')\n",
    "        yp75=np.percentile(y_sum[np.nonzero(y_sum)],75,interpolation='nearest')\n",
    "        # yp50=np.percentile(y_sum[np.nonzero(y_sum)],50,interpolation='nearest')\n",
    "        zp100=np.percentile(z_sum[np.nonzero(z_sum)],100,interpolation='nearest')\n",
    "        zp75=np.percentile(z_sum[np.nonzero(z_sum)],75,interpolation='nearest')\n",
    "        # zp50=np.percentile(z_sum[np.nonzero(z_sum)],50,interpolation='nearest')\n",
    "\n",
    "        x_idx = np.argwhere(x_sum==xp100)[0][0]\n",
    "        y_idx = np.argwhere(y_sum==yp100)[0][0]\n",
    "        z_idx = np.argwhere(z_sum==zp100)[0][0]\n",
    "\n",
    "        B = np.argwhere(mask[x_idx])\n",
    "        (xstart_x, ystart_x), (xstop_x, ystop_x) = B.min(0), B.max(0) + 1     \n",
    "        B = np.argwhere(mask[:,y_idx])\n",
    "        (xstart_y, ystart_y), (xstop_y, ystop_y) = B.min(0), B.max(0) + 1     \n",
    "        B = np.argwhere(mask[:,:,z_idx])\n",
    "        (xstart_z, ystart_z), (xstop_z, ystop_z) = B.min(0), B.max(0) + 1\n",
    "\n",
    "        FLAIR_x1 = zoompad(np.asarray(FLAIR_m[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "        FLAIR_y1 = zoompad(np.asarray(FLAIR_m[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "        FLAIR_z1 = zoompad(np.asarray(FLAIR_m[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "\n",
    "        T2_x1 = zoompad(np.asarray(T2_m[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "        T2_y1 = zoompad(np.asarray(T2_m[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "        T2_z1 = zoompad(np.asarray(T2_m[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "\n",
    "        T1_x1 = zoompad(np.asarray(T1_m[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "        T1_y1 = zoompad(np.asarray(T1_m[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "        T1_z1 = zoompad(np.asarray(T1_m[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "\n",
    "        T1post_x1 = zoompad(np.asarray(T1post_m[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "        T1post_y1 = zoompad(np.asarray(T1post_m[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "        T1post_z1 = zoompad(np.asarray(T1post_m[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "        \n",
    "        mask_x1 = zoompad(np.asarray(mask[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "        mask_y1 = zoompad(np.asarray(mask[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "        mask_z1 = zoompad(np.asarray(mask[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "\n",
    "        x_idx = np.argwhere(x_sum==xp75)[0][0]\n",
    "        y_idx = np.argwhere(y_sum==yp75)[0][0]\n",
    "        z_idx = np.argwhere(z_sum==zp75)[0][0]\n",
    "\n",
    "        B = np.argwhere(mask[x_idx])\n",
    "        (xstart_x, ystart_x), (xstop_x, ystop_x) = B.min(0), B.max(0) + 1     \n",
    "        B = np.argwhere(mask[:,y_idx])\n",
    "        (xstart_y, ystart_y), (xstop_y, ystop_y) = B.min(0), B.max(0) + 1     \n",
    "        B = np.argwhere(mask[:,:,z_idx])\n",
    "        (xstart_z, ystart_z), (xstop_z, ystop_z) = B.min(0), B.max(0) + 1\n",
    "\n",
    "        FLAIR_x2 = zoompad(np.asarray(FLAIR_m[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "        FLAIR_y2 = zoompad(np.asarray(FLAIR_m[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "        FLAIR_z2 = zoompad(np.asarray(FLAIR_m[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "\n",
    "        T2_x2 = zoompad(np.asarray(T2_m[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "        T2_y2 = zoompad(np.asarray(T2_m[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "        T2_z2 = zoompad(np.asarray(T2_m[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "\n",
    "        T1_x2 = zoompad(np.asarray(T1_m[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "        T1_y2 = zoompad(np.asarray(T1_m[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "        T1_z2 = zoompad(np.asarray(T1_m[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "\n",
    "        T1post_x2 = zoompad(np.asarray(T1post_m[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "        T1post_y2 = zoompad(np.asarray(T1post_m[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "        T1post_z2 = zoompad(np.asarray(T1post_m[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "        \n",
    "        mask_x2 = zoompad(np.asarray(mask[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "        mask_y2 = zoompad(np.asarray(mask[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "        mask_z2 = zoompad(np.asarray(mask[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "\n",
    "        # save in ascending order\n",
    "        slices_FLAIR[non_codel_factor*non_codel_counter] = np.stack((FLAIR_x2, FLAIR_y2, FLAIR_z2), axis=2)\n",
    "        slices_FLAIR[non_codel_factor*non_codel_counter+1] = np.stack((FLAIR_x1, FLAIR_y1, FLAIR_z1), axis=2)\n",
    "\n",
    "        slices_T2[non_codel_factor*non_codel_counter] = np.stack((T2_x2, T2_y2, T2_z2), axis=2)\n",
    "        slices_T2[non_codel_factor*non_codel_counter+1] = np.stack((T2_x1, T2_y1, T2_z1), axis=2)\n",
    "\n",
    "        slices_T1[non_codel_factor*non_codel_counter] = np.stack((T1_x2, T1_y2, T1_z2), axis=2)\n",
    "        slices_T1[non_codel_factor*non_codel_counter+1] = np.stack((T1_x1, T1_y1, T1_z1), axis=2)\n",
    "\n",
    "        slices_T1post[non_codel_factor*non_codel_counter] = np.stack((T1post_y2, T1post_y2, T1post_z2), axis=2)\n",
    "        slices_T1post[non_codel_factor*non_codel_counter+1] = np.stack((T1post_x1, T1post_y1, T1post_z1), axis=2)\n",
    "        \n",
    "        slices_mask[non_codel_factor*non_codel_counter] = np.stack((mask_y2, mask_y2, mask_z2), axis=2)\n",
    "        slices_mask[non_codel_factor*non_codel_counter+1] = np.stack((mask_x1, mask_y1, mask_z1), axis=2)\n",
    "\n",
    "        label_age[non_codel_factor*non_codel_counter:non_codel_factor*non_codel_counter+non_codel_factor] = curr_age\n",
    "        label_IDH1[non_codel_factor*non_codel_counter:non_codel_factor*non_codel_counter+non_codel_factor] = curr_idh1\n",
    "        label_1p19q[non_codel_factor*non_codel_counter:non_codel_factor*non_codel_counter+non_codel_factor] = curr_1p19q\n",
    "        label_IDH1_1p19q[non_codel_factor*non_codel_counter:non_codel_factor*non_codel_counter+non_codel_factor] = curr_IDH1_1p19q\n",
    "        label_OS[non_codel_factor*non_codel_counter:non_codel_factor*non_codel_counter+non_codel_factor] = curr_OS\n",
    "        label_gender[non_codel_factor*non_codel_counter:non_codel_factor*non_codel_counter+non_codel_factor] = curr_gender\n",
    "        label_KPS[non_codel_factor*non_codel_counter:non_codel_factor*non_codel_counter+non_codel_factor] = curr_KPS\n",
    "        label_id[non_codel_factor*non_codel_counter:non_codel_factor*non_codel_counter+non_codel_factor] = p\n",
    "        label_idstr[non_codel_factor*non_codel_counter:non_codel_factor*non_codel_counter+non_codel_factor] = patients[p]\n",
    "        \n",
    "        non_codel_counter += 1\n",
    "\n",
    "    elif curr_1p19q == 1:\n",
    "        #obtain top 30 mask area indices\n",
    "        x_ind_array = np.argpartition(x_sum,-codel_factor)[-codel_factor:]\n",
    "        x_ind_array = x_ind_array[np.argsort(x_sum[x_ind_array])]\n",
    "\n",
    "        y_ind_array = np.argpartition(y_sum,-codel_factor)[-codel_factor:]\n",
    "        y_ind_array = y_ind_array[np.argsort(y_sum[y_ind_array])]\n",
    "\n",
    "        z_ind_array = np.argpartition(z_sum,-codel_factor)[-codel_factor:]\n",
    "        z_ind_array = z_ind_array[np.argsort(z_sum[z_ind_array])]\n",
    "\n",
    "        for slice_ind in range(codel_factor): # store in ascending order\n",
    "\n",
    "            x_idx = x_ind_array[slice_ind]\n",
    "            y_idx = y_ind_array[slice_ind]\n",
    "            z_idx = z_ind_array[slice_ind]\n",
    "\n",
    "            B = np.argwhere(mask[x_idx]) # y-z plane\n",
    "            (xstart_x, ystart_x), (xstop_x, ystop_x) = B.min(0), B.max(0) + 1 \n",
    "            B = np.argwhere(mask[:,y_idx]) # x-z plane\n",
    "            (xstart_y, ystart_y), (xstop_y, ystop_y) = B.min(0), B.max(0) + 1 \n",
    "            B = np.argwhere(mask[:,:,z_idx]) # x-y plane\n",
    "            (xstart_z, ystart_z), (xstop_z, ystop_z) = B.min(0), B.max(0) + 1\n",
    "\n",
    "            FLAIR_x = zoompad(np.asarray(FLAIR_m[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "            FLAIR_y = zoompad(np.asarray(FLAIR_m[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "            FLAIR_z = zoompad(np.asarray(FLAIR_m[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "\n",
    "            T2_x = zoompad(np.asarray(T2_m[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "            T2_y = zoompad(np.asarray(T2_m[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "            T2_z = zoompad(np.asarray(T2_m[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "\n",
    "            T1_x = zoompad(np.asarray(T1_m[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "            T1_y = zoompad(np.asarray(T1_m[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "            T1_z = zoompad(np.asarray(T1_m[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "\n",
    "            T1post_x = zoompad(np.asarray(T1post_m[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "            T1post_y = zoompad(np.asarray(T1post_m[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "            T1post_z = zoompad(np.asarray(T1post_m[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "            \n",
    "            mask_x = zoompad(np.asarray(mask[x_idx][xstart_x:xstop_x, ystart_x:ystop_x]), desired_size)\n",
    "            mask_y = zoompad(np.asarray(mask[:,y_idx][xstart_y:xstop_y, ystart_y:ystop_y]), desired_size)\n",
    "            mask_z = zoompad(np.asarray(mask[:,:,z_idx][xstart_z:xstop_z, ystart_z:ystop_z]), desired_size)\n",
    "\n",
    "            slices_FLAIR_codel[codel_factor*codel_counter + slice_ind] = np.stack((FLAIR_x, FLAIR_y, FLAIR_z), axis=2)\n",
    "            slices_T2_codel[codel_factor*codel_counter + slice_ind] = np.stack((T2_x, T2_y, T2_z), axis=2)\n",
    "            slices_T1_codel[codel_factor*codel_counter + slice_ind] = np.stack((T1_x, T1_y, T1_z), axis=2)\n",
    "            slices_T1post_codel[codel_factor*codel_counter + slice_ind] = np.stack((T1post_x, T1post_y, T1post_z), axis=2)\n",
    "            slices_mask_codel[codel_factor*codel_counter + slice_ind] = np.stack((mask_x, mask_y, mask_z), axis=2)\n",
    "            used_sl_idx_arr = np.append(used_sl_idx_arr,y_idx)\n",
    "        print(\"Done saving 20 slices\")\n",
    "\n",
    "\n",
    "        label_age_codel[codel_factor*codel_counter:codel_factor*codel_counter+codel_factor] = curr_age\n",
    "        label_IDH1_codel[codel_factor*codel_counter:codel_factor*codel_counter+codel_factor] = curr_idh1\n",
    "        label_1p19q_codel[codel_factor*codel_counter:codel_factor*codel_counter+codel_factor] = curr_1p19q\n",
    "        label_IDH1_1p19q_codel[codel_factor*codel_counter:codel_factor*codel_counter+codel_factor] = curr_IDH1_1p19q\n",
    "        label_OS_codel[codel_factor*codel_counter:codel_factor*codel_counter+codel_factor] = curr_OS\n",
    "        label_gender_codel[codel_factor*codel_counter:codel_factor*codel_counter+codel_factor] = curr_gender\n",
    "        label_KPS_codel[codel_factor*codel_counter:codel_factor*codel_counter+codel_factor] = curr_KPS\n",
    "        label_id_codel[codel_factor*codel_counter:codel_factor*codel_counter+codel_factor] = p\n",
    "        label_idstr_codel[codel_factor*codel_counter:codel_factor*codel_counter+codel_factor] = patients[p]\n",
    "        \n",
    "        codel_counter += 1\n",
    "\n",
    "    print(\"Done patient number: \", p)\n",
    "    del FLAIR, T2, T1, T1post, mask, curr_age, curr_idh1, curr_1p19q, curr_IDH1_1p19q, curr_OS, curr_KPS,curr_gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(used_sl_idx_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine codel and non-codel together\n",
    "slices_FLAIR_comb = np.vstack((slices_FLAIR,slices_FLAIR_codel))\n",
    "slices_T1_comb = np.vstack((slices_T1,slices_T1_codel))\n",
    "slices_T1post_comb = np.vstack((slices_T1post,slices_T1post_codel))\n",
    "slices_T2_comb = np.vstack((slices_T2,slices_T2_codel))\n",
    "slices_mask_comb = np.vstack((slices_mask,slices_mask_codel))\n",
    "\n",
    "label_age_comb = np.append(label_age, label_age_codel)\n",
    "label_IDH1_comb = np.append(label_IDH1,label_IDH1_codel)\n",
    "label_1p19q_comb = np.append(label_1p19q,label_1p19q_codel)\n",
    "label_gender_comb = np.append(label_gender, label_gender_codel)\n",
    "label_KPS_comb = np.append(label_KPS, label_KPS_codel)\n",
    "label_OS_comb = np.append(label_OS, label_OS_codel)\n",
    "label_IDH1_1p19q_comb = np.append(label_IDH1_1p19q, label_IDH1_1p19q_codel)\n",
    "label_id_comb = np.append(label_id, label_id_codel)\n",
    "label_idstr_comb = np.append(label_idstr, label_idstr_codel)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#os.chdir(savedir)\n",
    "os.chdir(savedir)\n",
    "np.save('slices_FLAIR.npy', slices_FLAIR_comb)\n",
    "np.save('slices_T2.npy', slices_T2_comb)\n",
    "np.save('slices_T1.npy', slices_T1_comb)\n",
    "np.save('slices_T1post.npy', slices_T1post_comb)\n",
    "np.save('slices_mask.npy', slices_mask_comb)\n",
    "\n",
    "np.save('label_age.npy',label_age_comb)\n",
    "np.save('label_IDH1.npy', label_IDH1_comb)\n",
    "np.save('label_1p19q.npy', label_1p19q_comb)\n",
    "np.save('label_IDH1_1p19q.npy', label_IDH1_1p19q_comb)\n",
    "np.save('label_OS.npy', label_OS_comb)\n",
    "np.save('label_gender.npy', label_gender_comb)\n",
    "np.save('label_KPS.npy', label_KPS_comb)\n",
    "np.save('label_id.npy', label_id_comb)\n",
    "np.save('label_idstr.npy', label_idstr_comb)\n",
    "np.savetxt('label_idstr.csv', label_idstr_comb,delimiter=',',fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed version of the slice selection\n",
    "# expands the images for later perturbation analysis\n",
    "\n",
    "\n",
    "modal_list = ['FLAIR','T1', 'T1post','T2']\n",
    "slices = {}\n",
    "codel_factor = 20\n",
    "desired_size=[142,142]\n",
    "exp_c = .5 # expansion coefficient on each side of the image\n",
    "exp_size = [np.int(sz*(1+(exp_c*2))) for sz in desired_size] #[284, 284] for 50% expansion\n",
    "\n",
    "codel_slices = num_codel*codel_factor \n",
    "noncodel_slices = num_non_codel*non_codel_factor\n",
    "total_slices = codel_slices + noncodel_slices\n",
    "exp_slice_dict = {}\n",
    "exp_mask_arr = np.empty((total_slices,exp_size[0],exp_size[1],3))\n",
    "for modal in modal_list:\n",
    "    exp_slice_dict[modal] = np.empty((total_slices,exp_size[0],exp_size[1],3))\n",
    "    \n",
    "labels = {}\n",
    "labels['age'] = np.empty(total_slices)\n",
    "labels['IDH1'] = np.empty(total_slices)\n",
    "labels['1p19q'] = np.empty(total_slices)\n",
    "labels['IDH1_1p19q'] = np.empty(total_slices)\n",
    "labels['OS'] = np.empty(total_slices)\n",
    "labels['gender'] = np.empty(total_slices)\n",
    "labels['KPS'] = np.empty(total_slices) \n",
    "labels['id'] = np.empty(total_slices) \n",
    "labels['idstr'] = np.empty(total_slices,dtype=object) \n",
    "\n",
    "used_sl_idx_arr = np.empty((0,1))\n",
    "\n",
    "# taking the slices in different directions\n",
    "# we'll be looking at the volume in different orientations, with slices in the 2nd and 3rd dimensions\n",
    "# yeah, that's unorthodox, but donnie wrote hard-coded it this way and I don't want to rearchitect everything\n",
    "# First orientation is sagittal (y,z)\n",
    "# second orientation is coronal (x,z)\n",
    "# third orientation is axial (x,y)\n",
    "# PS: I hate 0 indexing\n",
    "# ori_arr = {'sag':(0,2,1),'cor':(1,2,0),'axi':(2,0,1)}\n",
    "# dim_arr = ((0,2,1),(1,2,0),(2,0,1)) # proper standard orientations\n",
    "\n",
    "# matching the weird orientation donnie has the slices in\n",
    "dim_arr = ((0,1,2),(1,0,2),(2,0,1))\n",
    "\n",
    "codel_counter = 0\n",
    "non_codel_counter = 0\n",
    "# p = 88\n",
    "# if 1:\n",
    "for p in range(len(patients)):\n",
    "    p_id = patients[p]\n",
    "    patient_dir = os.path.join(normdir,p_dirs[p])\n",
    "    #patient_dir = os.path.join(imagedir,p_dirs[p])\n",
    "\n",
    "    print(p, p_id,patient_dir)\n",
    "    idx_idh1=np.asarray(np.where((patient_IDH[:,0].astype(str))==str(p_id)))\n",
    "    if (idx_idh1.size == 0): # not found in the spreadsheet\n",
    "        print(\"\\\"%s\\\" not found in Excel Spreadsheet\" % (p_id))\n",
    "    #    continue # skip this folder\n",
    "\n",
    "    curr_idh1 = patient_IDH[idx_idh1,1]\n",
    "    if curr_idh1 == 'WT':\n",
    "        curr_idh1 = 0\n",
    "    elif curr_idh1 == 'Mutant':\n",
    "        curr_idh1 = 1\n",
    "    elif not (curr_idh1 == 1 or curr_idh1 == 0):\n",
    "        curr_idh1 = float('nan')\n",
    "\n",
    "    idx_age=np.asarray(np.where((patient_age[:,0].astype(str))==str(p_id)))\n",
    "    curr_age = patient_age[idx_age,1]\n",
    "\n",
    "    idx_1p19q=np.asarray(np.where((patient_1p19q[:,0].astype(str))==str(p_id)))\n",
    "    curr_1p19q = patient_1p19q[idx_1p19q,1]\n",
    "    print(p_id,curr_1p19q)\n",
    "    \n",
    "    idx_IDH1_1p19q=np.asarray(np.where((patient_IDH1_1p19q[:,0].astype(str))==str(p_id)))\n",
    "    curr_IDH1_1p19q = patient_IDH1_1p19q[idx_IDH1_1p19q,1]\n",
    "    if curr_IDH1_1p19q == 'IDHwt':\n",
    "        curr_IDH1_1p19q = 0\n",
    "    elif curr_IDH1_1p19q == 'IDHmut-non-codel':\n",
    "        curr_IDH1_1p19q = 1\n",
    "    elif curr_IDH1_1p19q == 'IDHmut-codel':\n",
    "        curr_IDH1_1p19q = 2\n",
    "    elif not (curr_IDH1_1p19q == 1 or curr_IDH1_1p19q == 0):\n",
    "        curr_IDH1_1p19q = float('nan')\n",
    "\n",
    "    idx_OS=np.asarray(np.where((patient_OS[:,0].astype(str))==str(p_id)))\n",
    "    curr_OS = patient_OS[idx_OS,1]\n",
    "\n",
    "    idx_gender=np.asarray(np.where((patient_gender[:,0].astype(str))==str(p_id)))\n",
    "    input_gender=patient_gender[idx_gender,1] # if handling a string, and you put in a float, things get ugly when you delete\n",
    "    if input_gender == 'male':\n",
    "        curr_gender = np.float64(0)\n",
    "    elif input_gender == 'female':\n",
    "        curr_gender = np.float64(1)\n",
    "    elif not (input_gender == 1 or input_gender == 0):\n",
    "        curr_gender = float('nan')\n",
    "        #print('nan')\n",
    "    else:\n",
    "        curr_gender = input_gender\n",
    "\n",
    "    if not (curr_gender == 1 or curr_gender == 0):\n",
    "        print(curr_gender)\n",
    "    idx_KPS=np.asarray(np.where((patient_KPS[:,0].astype(str))==str(p_id)))\n",
    "    curr_KPS=patient_KPS[idx_KPS,1]\n",
    "\n",
    "#     cImg = np.load(os.path.join(patient_dir,'%s_normssn4.npy' % modal))\n",
    "    mask = np.load(os.path.join(patient_dir,'truth.npy'))\n",
    "\n",
    "    # loading from NIFTI file format\n",
    "    #file_name= os.path.join(patient_dir,'%s.nii.gz' % (modal))\n",
    "    #cImg = nib.load(file_name).get_data()\n",
    "    #mask_name= os.path.join(patient_dir,'truth.nii.gz')\n",
    "    #mask = nib.load(mask_name).get_data()\n",
    "    for modal in modal_list:\n",
    "        #os.chdir(patient_dir)\n",
    "        cImg = np.load(os.path.join(patient_dir,'%s_normssn4.npy' % modal))\n",
    "#         mask = np.load(os.path.join(patient_dir,'truth.npy'))\n",
    "\n",
    "\n",
    "#         dN = 1\n",
    "#         if 1:\n",
    "        for dN in range(len(dim_arr)):\n",
    "            # permute/transpose image so that it's in a standard orientation\n",
    "            tImg = np.transpose(cImg,axes = dim_arr[dN])\n",
    "            tMask = np.transpose(mask,axes = dim_arr[dN])\n",
    "            # count the # of cancer pixels per slice\n",
    "            m_sum = np.sum(tMask>0,axis=(1,2))\n",
    "\n",
    "            if curr_1p19q == 0:\n",
    "                # get the list of indices\n",
    "                m_perc=np.percentile(m_sum[np.nonzero(m_sum)],(75,100),interpolation='nearest')\n",
    "                ind_array = np.asarray([abs(m_sum-p).argmin() for p in m_perc]) # list comprehension to get the indices\n",
    "                cNSlices = non_codel_factor\n",
    "            else:\n",
    "                # sort the indices by the # of tumor pixels\n",
    "                ind_array = np.argpartition(m_sum,-codel_factor)[-codel_factor:]\n",
    "                ind_array = ind_array[np.argsort(m_sum[ind_array])]\n",
    "                cNSlices = codel_factor\n",
    "\n",
    "            # print(ind_array.shape)\n",
    "            for slice_ind in range(cNSlices):\n",
    "\n",
    "                # look at the volume slice by slice\n",
    "                c_idx = ind_array[slice_ind]\n",
    "\n",
    "                # take slices from the transposed image\n",
    "                img_slice = tImg[c_idx,:,:]\n",
    "                mask_slice = tMask[c_idx,:,:]\n",
    "\n",
    "                # get the bounding box indices of the tumor\n",
    "\n",
    "                xrange = np.empty((2))\n",
    "                yrange = np.empty((2))\n",
    "                B = np.argwhere(tMask[c_idx])\n",
    "                (yrange[0],xrange[0]), (yrange[1], xrange[1]) = B.min(0), B.max(0) + 1 \n",
    "                # get the size of the image in \n",
    "                xdiff = xrange[1]-xrange[0]\n",
    "                ydiff = yrange[1]-yrange[0]\n",
    "                # find the padded image range\n",
    "                xexp = (xrange[0] - (xdiff * exp_c),xrange[1] + (xdiff * exp_c))\n",
    "                yexp = (yrange[0] - (ydiff * exp_c),yrange[1] + (ydiff * exp_c))\n",
    "\n",
    "                # build the vectors and meshes to sample\n",
    "                xIV = np.linspace(xexp[0],xexp[1],exp_size[1])\n",
    "                yIV = np.linspace(yexp[0],yexp[1],exp_size[0])\n",
    "                (xm,ym) = np.meshgrid(xIV, yIV)\n",
    "                # sample at the mesh locations, this one is spline interpolation\n",
    "                tr_im = ndimage.map_coordinates(img_slice,[ym, xm])\n",
    "\n",
    "                (xorm,yorm) = np.meshgrid(range(img_slice.shape[0]), range(img_slice.shape[1]))\n",
    "                # this is the original schema for sampling\n",
    "                # cropped exactly to the tumor\n",
    "                xcrIV = np.linspace(xrange[0],xrange[1],desired_size[1])\n",
    "                ycrIV = np.linspace(yrange[0],yrange[1],desired_size[0])\n",
    "                (xcrm,ycrm) = np.meshgrid(xcrIV, ycrIV)\n",
    "                cr_im = ndimage.map_coordinates(img_slice,[ycrm, xcrm])\n",
    "\n",
    "                # sample the mask at the same locations\n",
    "                # order = 0 is to make it categorical in its output (not 100% that's the setting, I know how to do it in MATLAB)\n",
    "                tr_mask = ndimage.map_coordinates(mask_slice,[ym, xm],order = 0)\n",
    "                cr_mask = ndimage.map_coordinates(mask_slice,[ycrm, xcrm],order = 0)\n",
    "                #cr_mask = interpolate.interpn([yorm,xorm],mask_slice,[ycrm, xcrm])\n",
    "\n",
    "                if curr_1p19q == 0: # this is a VERY UGLY way of doing things\n",
    "                    # I generally disagree with the stack all the slices into one pile approach, due to it's lack of flexibility\n",
    "                    # This is illustrative of some of the issues that emerge\n",
    "                    # This indexing makes it so if we change anything, it's very brittle\n",
    "                    # I'd much rather handle \n",
    "                    cSliceIdx = slice_ind + (non_codel_counter * non_codel_factor)\n",
    "                else:\n",
    "                    cSliceIdx = slice_ind + (noncodel_slices) + (codel_counter * codel_factor)\n",
    "\n",
    "                #print(cSliceIdx)\n",
    "                \n",
    "                ## record the slices and masks\n",
    "                exp_slice_dict[modal][cSliceIdx,:,:,dN] = tr_im\n",
    "                exp_mask_arr[cSliceIdx,:,:,dN] = tr_mask\n",
    "                ## record the demographics\n",
    "                labels['age'][cSliceIdx]        = curr_age\n",
    "                labels['IDH1'][cSliceIdx]       = curr_idh1\n",
    "                labels['1p19q'][cSliceIdx]      = curr_1p19q\n",
    "                labels['IDH1_1p19q'][cSliceIdx] = curr_IDH1_1p19q\n",
    "                labels['OS'][cSliceIdx]         = curr_OS\n",
    "                labels['gender'][cSliceIdx]     = curr_gender\n",
    "                labels['KPS'][cSliceIdx]        = curr_KPS\n",
    "                labels['id'][cSliceIdx]         = p\n",
    "                labels['idstr'][cSliceIdx]      = patients[p]\n",
    "                if (slice_ind == -1):\n",
    "                    print(xrange,yrange)\n",
    "                    print(xdiff,ydiff)\n",
    "                    print(xexp,yexp)\n",
    "\n",
    "                    plt.imshow(img_slice, cmap=\"gray\", origin=\"lower\")\n",
    "                    plt.show()\n",
    "                    plt.imshow(tr_im, cmap=\"gray\", origin=\"lower\")\n",
    "                    plt.show()\n",
    "                    plt.imshow(cr_im, cmap=\"gray\", origin=\"lower\")\n",
    "                    plt.show()\n",
    "                    plt.imshow(mask_slice, cmap=\"gray\", origin=\"lower\")\n",
    "                    plt.clim(0,4)\n",
    "                    plt.show()\n",
    "                    plt.imshow(tr_mask, cmap=\"gray\", origin=\"lower\")\n",
    "                    plt.clim(0,4)\n",
    "                    plt.show()\n",
    "                    plt.imshow(cr_mask, cmap=\"gray\", origin=\"lower\")\n",
    "                    plt.clim(0,4)\n",
    "                    plt.show()\n",
    "    if curr_1p19q == 0:\n",
    "        non_codel_counter += 1\n",
    "    else:\n",
    "        codel_counter += 1\n",
    "\n",
    "os.chdir(savedir)\n",
    "np.save('slices_exp_FLAIR.npy', exp_slice_dict['FLAIR'])\n",
    "np.save('slices_exp_T2.npy', exp_slice_dict['T2'])\n",
    "np.save('slices_exp_T1.npy', exp_slice_dict['T1'])\n",
    "np.save('slices_exp_T1post.npy', exp_slice_dict['T1post'])\n",
    "np.save('slices_exp_mask.npy', exp_mask_arr)\n",
    "\n",
    "# np.save('label_age.npy',label_age_comb)\n",
    "# np.save('label_IDH1.npy', label_IDH1_comb)\n",
    "# np.save('label_1p19q.npy', label_1p19q_comb)\n",
    "# np.save('label_IDH1_1p19q.npy', label_IDH1_1p19q_comb)\n",
    "# np.save('label_OS.npy', label_OS_comb)\n",
    "# np.save('label_gender.npy', label_gender_comb)\n",
    "# np.save('label_KPS.npy', label_KPS_comb)\n",
    "# np.save('label_id.npy', label_id_comb)\n",
    "# np.save('label_idstr.npy', label_idstr_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for dN in range(3):\n",
    "    plt.imshow(exp_slice_dict['FLAIR'][260,:,:,dN], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.show()\n",
    "    plt.imshow(slices_FLAIR_comb[260,:,:,dN], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.show()\n",
    "    plt.imshow(exp_mask_arr[260,:,:,dN], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.clim(0,1)\n",
    "    plt.show()\n",
    "    plt.imshow(slices_mask_comb[260,:,:,dN], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice_num = 20 \n",
    "# cv_num = 13\n",
    "\n",
    "# for i in range(cv_num): # split between train and test 13 times\n",
    "\n",
    "#     # assign indices for train,val, and test datasets in non-overlapping fashion\n",
    "#     ind_test = range(i* slice_num, i*slice_num + slice_num)\n",
    "#     if i == cv_num-1:\n",
    "#         ind_val = range(0,slice_num)\n",
    "#     else:\n",
    "#         ind_val = range(i*slice_num + slice_num, i*slice_num + 2*slice_num)\n",
    "\n",
    "#     ind_test_val = set(ind_test).union(set(ind_val))\n",
    "\n",
    "#     ind_train = list(set(ind_test_val).symmetric_difference(ind_list))\n",
    "\n",
    "#     # test data\n",
    "#     ind_shuffled = shuffle(range(40))\n",
    "#     print(ind_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
